# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xXRocNat_9S0ib3J_Pfws9V9cPLGqVqq
"""

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt
import os
import tensorflow_datasets as tfds
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr
from tensorflow.keras.applications import VGG19
from tensorflow.keras.models import Model

# Load dataset
data = tfds.load("imagenette/320px", split="train", as_supervised=True)

def preprocess(img, label):
    img = tf.image.resize(img, (64, 64))
    img = tf.cast(img, tf.float32) / 255.0
    img_gray = tf.image.rgb_to_grayscale(img)
    return img_gray, img

data = data.map(preprocess).batch(64).prefetch(tf.data.AUTOTUNE)

# Attention block with resizing
from tensorflow.keras.layers import Lambda

def attention_block(x, g, inter_channels, resize_shape):
    theta = layers.Conv2D(inter_channels, 1, padding='same')(x)
    phi = layers.Conv2D(inter_channels, 1, padding='same')(g)
    phi = tf.keras.layers.Resizing(resize_shape[0], resize_shape[1], interpolation='bilinear')(phi)
    attn = layers.Activation('relu')(layers.Add()([theta, phi]))
    attn = layers.Conv2D(1, 1, activation='sigmoid')(attn)
    out = layers.Multiply()([x, attn])
    return out

# U-Net-like Generator with attention
def build_generator(input_shape=(64, 64, 1)):
    inputs = tf.keras.Input(shape=input_shape)

    # Encoder
    x1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)
    x1_pool = layers.MaxPooling2D((2, 2))(x1)  # 32x32

    x2 = layers.Conv2D(128, 3, activation='relu', padding='same')(x1_pool)
    x2_pool = layers.MaxPooling2D((2, 2))(x2)  # 16x16

    x3 = layers.Conv2D(256, 3, activation='relu', padding='same')(x2_pool)
    x3_pool = layers.MaxPooling2D((2, 2))(x3)  # 8x8

    # Bottleneck
    x4 = layers.Conv2D(512, 3, activation='relu', padding='same')(x3_pool)

    # Decoder
    u3 = layers.Conv2DTranspose(256, 3, strides=2, padding='same', activation='relu')(x4)  # 16x16
    att3 = attention_block(x3, u3, 128, resize_shape=(16, 16))
    u3 = layers.Concatenate()([u3, att3])

    u2 = layers.Conv2DTranspose(128, 3, strides=2, padding='same', activation='relu')(u3)  # 32x32
    att2 = attention_block(x2, u2, 64, resize_shape=(32, 32))
    u2 = layers.Concatenate()([u2, att2])

    u1 = layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(u2)  # 64x64
    att1 = attention_block(x1, u1, 32, resize_shape=(64, 64))
    u1 = layers.Concatenate()([u1, att1])

    outputs = layers.Conv2D(3, 1, activation='sigmoid', padding='same')(u1)

    return tf.keras.Model(inputs, outputs)

# Simple Discriminator
def build_discriminator(input_shape=(64, 64, 3)):
    inputs = tf.keras.Input(shape=input_shape)
    x = layers.Conv2D(64, 4, strides=2, padding='same', activation='relu')(inputs)
    x = layers.Conv2D(128, 4, strides=2, padding='same', activation='relu')(x)
    x = layers.Conv2D(256, 4, strides=2, padding='same', activation='relu')(x)
    x = layers.Flatten()(x)
    x = layers.Dense(1, activation='sigmoid')(x)
    return tf.keras.Model(inputs, x)

# === Load VGG for perceptual loss ===
vgg = VGG19(include_top=False, weights='imagenet', input_shape=(64, 64, 3))
vgg.trainable = False
perceptual_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)

generator = build_generator()
discriminator = build_discriminator()

loss_fn = tf.keras.losses.BinaryCrossentropy()
gen_optimizer = tf.keras.optimizers.Adam(1e-4)
disc_optimizer = tf.keras.optimizers.Adam(1e-4)

from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr

# === Training with early stopping ===
EPOCHS = 200
best_psnr = 0
patience = 7
wait = 0

for epoch in range(EPOCHS):
    print(f"Epoch {epoch+1}/{EPOCHS}")
    epoch_gen_loss, epoch_disc_loss = 0, 0
    all_psnr, all_ssim = [], []
    total_batches = 0

    for x_gray, x_real in data:
        total_batches += 1

        # Train Discriminator
        with tf.GradientTape() as tape:
            x_fake = generator(x_gray, training=True)
            real_logits = discriminator(x_real, training=True)
            fake_logits = discriminator(x_fake, training=True)
            disc_loss = loss_fn(tf.ones_like(real_logits) * 0.9, real_logits) + \
                        loss_fn(tf.zeros_like(fake_logits), fake_logits)
        grads = tape.gradient(disc_loss, discriminator.trainable_variables)
        disc_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))

        # Train Generator
        with tf.GradientTape() as tape:
            x_fake = generator(x_gray, training=True)
            fake_logits = discriminator(x_fake, training=True)
            gan_loss = loss_fn(tf.ones_like(fake_logits), fake_logits)
            l1_loss = tf.reduce_mean(tf.abs(x_real - x_fake))
            real_feat = perceptual_model(x_real)
            fake_feat = perceptual_model(x_fake)
            perceptual_loss = tf.reduce_mean(tf.abs(real_feat - fake_feat))
            gen_loss = gan_loss + 100 * l1_loss + 10 * perceptual_loss
        grads = tape.gradient(gen_loss, generator.trainable_variables)
        gen_optimizer.apply_gradients(zip(grads, generator.trainable_variables))

        epoch_gen_loss += gen_loss.numpy()
        epoch_disc_loss += disc_loss.numpy()

        x_fake_np = x_fake.numpy()
        x_real_np = x_real.numpy()
        for i in range(x_real_np.shape[0]):
            all_psnr.append(psnr(x_real_np[i], x_fake_np[i]))
            all_ssim.append(ssim(x_real_np[i], x_fake_np[i], win_size=7, channel_axis=-1, data_range=1.0))

    avg_gen_loss = epoch_gen_loss / total_batches
    avg_disc_loss = epoch_disc_loss / total_batches
    avg_psnr = np.mean(all_psnr)
    avg_ssim = np.mean(all_ssim)

    print(f"Generator Loss: {avg_gen_loss:.4f}, Discriminator Loss: {avg_disc_loss:.4f}, PSNR: {avg_psnr:.2f}, SSIM: {avg_ssim:.4f}")

    if avg_psnr > best_psnr:
        best_psnr = avg_psnr
        wait = 0
        generator.save("best_generator.keras")
        discriminator.save("best_discriminator.keras")
    else:
        wait += 1
        if wait >= patience:
            print("Early stopping triggered.")
            break

    # Plot example outputs
    if (epoch + 1) % 5 == 0 or epoch == 0:
        sample_gray = x_gray[:5]
        sample_fake = generator.predict(sample_gray)
        plt.figure(figsize=(15, 3))
        for i in range(5):
            plt.subplot(3, 5, i+1)
            plt.imshow(tf.squeeze(sample_gray[i]), cmap='gray')
            plt.axis('off')
            plt.subplot(3, 5, i+6)
            plt.imshow(np.clip(sample_fake[i], 0, 1))
            plt.axis('off')
            plt.subplot(3, 5, i+11)
            plt.imshow(x_real[i])
            plt.axis('off')
        plt.tight_layout()
        plt.show()

# Generate final comparison after training
sample_gray, sample_real = next(iter(data))
sample_fake = generator.predict(sample_gray)

plt.figure(figsize=(15, 3))
for i in range(5):
    # Grayscale input
    plt.subplot(3, 5, i+1)
    plt.imshow(tf.squeeze(sample_gray[i]), cmap='gray')
    plt.axis('off')
    if i == 0:
        plt.title("Input (Gray)")

    # Generated image
    plt.subplot(3, 5, i+6)
    plt.imshow(np.clip(sample_fake[i], 0, 1))  # clip just in case
    plt.axis('off')
    if i == 0:
        plt.title("Generated")

    # Ground truth
    plt.subplot(3, 5, i+11)
    plt.imshow(sample_real[i])
    plt.axis('off')
    if i == 0:
        plt.title("Ground Truth")

plt.suptitle("Final Output Comparison", fontsize=16)
plt.tight_layout()
plt.show()
